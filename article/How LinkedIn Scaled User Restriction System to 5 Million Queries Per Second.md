# [How LinkedIn Scaled User Restriction System to 5 Million Queries Per Second](https://blog.bytebytego.com/p/how-linkedin-scaled-user-restriction)
- LinkedIn은 어떻게 사용자 제한 시스템을 5백만 QPS까지 확장하였을까?
- CASAL(Community Abuse and Safety Application Layer): 악의적인 사용자 및 적대적인 공격으로부터 방어하는 첫 번째 방어선

### 1세대
1. Oracle
  - 제한 정책을 위해 RDBMS 사용
  - 높은 처리량과 낮은 지연시간을 유지하기에는 한계가 있었음.
2. Server-Side Cache (인메모리 캐시) 추가
  - 데이터 요청 시, 캐시를 먼저 조회하고, 없으면 DB 조회
  - 낮은 트래픽에서는 잘 작동했지만, 캐시 히트가 높은 트래픽을 감당하기 어려웠음.
3. Client-Side Cache 추가
  - 클라이언트 측에 로컬 캐시 추가
  - 클라이언트와 서버 간 캐시 일관성이 까다로워짐.
  - 캐시를 다시 로드하거나 서버 재시작 시, 캐시를 새로 가져오는 작업이 DB에 부하를 주었음.
4. Full Refresh-Ahead Cache
  - 모든 클라이언트는 로컬 캐싱을 함.
  - 폴링을 통해 캐시 유효성을 확인
  - 사용자 응답 시간에는 좋은 효과를 보였음. (네트워크 호출이 없기 때문)
  - 메모리 사용량 증가
  - 애플리케이션 재시작 혹은 배포 시, 모든 데이터를 다시 로드하는데 리소스 소비가 크게 발생
    - Oracle DB에 부담
5. Bloom Filter
  - 전체 데이터셋을 저장하는 대신, 메모리 효율적으로 인코딩
  - 메모리 사용량 감소
  - 필터가 부정확하게 작동할 가능성이 있음

### 2세대
- 기존 RDBMS로는 10억 명의 요청을 처리하는데 한계를 인식
- 2세대의 목표
  - 높은 QPS(4~5백만)
  - 초저지연(<5ms)
  - 높은 가용성(99.999%)
  - 수평적 확장 가능
  - 데이터 동기화(일관성 보장)
1. NoSQL 분산 시스템 채택: `Espresso`(자체 구축) + `Kafka`
  - 일관성을 유지하면서 Oracle보다 좋은 확장성과 성능
  - Kafka와 긴밀한 통합
  - 새로운 record가 생성될 때마다, Kafka 메시지 송신
  - Kafka를 통해 여러 서버에 걸친 실시간 동기화
  - 그러나, 재시작 등의 부트스트래핑 중에 모든 데이터를 메모리에 적재하면서 DB에 부하를 크게 줌. 30분 이상 소요되기도 함.
  - 수평적 확장은 가능했지만 여전히 처리량에 한계가 있었음
2. CAP 이론
  - C 일관성: 모든 읽기 작업이 가장 최근의 쓰기 작업을 받거나 오류를 받아야 한다.
  - A 가용성: 각 요청이 개별 노드의 상태에 관계없이 오류가 아닌 응답을 받아야 한다.
  - P 내결함성: 네트워크 단절이 발생하더라도 시스템이 계속 동작한다.
  - 위 3가지 중 2가지만 달성 가능하다는 이론
  - LinkedIn은 CA를 우선함. 초저지연과 가용성 목표에 기반.
  - P 상황에서 Latency가 크게 늘어나는 현상을 관측한 적이 있음. 이는 2세대 목표와 위배.

### 3세대
- 증가하는 데이터 양과 적대적 공격으로 부담이 올라갔음.
- 목표
  - 메모리 사용 최적화
  - 복원력(resilience) 개선
  - 부트스트랩 프로세스 가속화
1. Off-Heap Memory 최적화
  - 2세대의 주요 병목 중 하나는 데이터 저장을 위한 힙 내 메모리 의존성
  - GC 주기로 인해 응답 시간의 스파이크가 생기거나 시스템 성능이 저하되었음.
  - 이를 해결하기 위해 데이터 저장을 off-heap memory로 이동하였음.
    - off-heap memory는 JVM 제어 바깥에 있음.
    - 따라서 GC의 빈도와 강도를 줄일 수 있었음.
  - 장점
    - JVM 힙을 과부하시키지 않고 더 많은 공간 사용 가능
    - GC를 줄임
    - 더 많은 데이터 처리 가능
2. Venice / DaVinci 프레임워크
  - 시스템 최적화를 위해 DaVinci라는 클라이언트 라이브러리를 개발
  - Venice와 통합됨
  - DaVinCi
    - eager cache. 시작 시에 모든 데이터를 메모리로 로드함.
    - 비트셋과 유사한 데이터 구조에 저장하여 메모리 효율을 높임
  - Venice
    - 파생 데이터를 위한 분산 플랫폼
    - 이를 통해 DaVinci가 데이터를 효율적으로 가져오고 저장할 수 있음.
    - 높은 속도와 성능 보장
  - 장점
    - 더 빠른 부트스트래핑 프로세스
      - 서버 시작 시, 더 빠른 메모리 로드
    - 더 큰 복원력

### 결론: LinkedIn의 아키텍처 개선 원칙
- 단순하게 시작하고, 신중하게 확장하기: 초기 설계는 복잡성을 줄이고 즉각적인 문제 해결에 중점
- 문제의 사전 식별
- 팀 간 협업: 지식 전파, 중복된 노력을 줄임
- 벤치마킹과 테스트
- 지속적인 개선: 이전 시스템의 성공과 단점을 바탕으로 구축

---

### Comment
- 더 많은 처리를 위해 low-level까지 고려하며 직접 라이브러리를 개발하는 것이 인상 깊었다.
  - 주로 서비스 개발을 하는 입장에서 저런게 진짜 개발이 아닐까 싶은 생각이 든다.
- 다만, 상세 내용이 드러나지 않아 어떻게 메모리 효율을 높였고, 어떻게 빠르게 동기화했는지 구체적으로 나오지 않아 아쉽다.
  - off-heap, kafka 동기화, espresso가 다른 NoSQL과 어떻게 다른지 등등