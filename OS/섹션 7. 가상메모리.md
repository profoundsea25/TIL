> [그림으로 쉽게 배우는 운영체제](https://www.inflearn.com/course/%EB%B9%84%EC%A0%84%EA%B3%B5%EC%9E%90-%EC%9A%B4%EC%98%81%EC%B2%B4%EC%A0%9C/dashboard) 요약입니다.

# 섹션 7. 가상메모리
## 가상메모리 개요
- 가상메모리의 크기는 이론적으로 무한대이지만 실제로는 물리 메모리 크기와 CPU의 비트 수로 결정됨
- 가상메모리의 크기가 클 경우 물리메모리 내용의 일부를 하드 디스크에 있는 스왑 영역으로 옮기고 처리가 필요할 때 물리 메모리로 가져와 실행시킴
- 동적주소변환(Dynamic Address Translation) : 메모리 관리자가 물리메모리와 스왑영역을 합쳐서 프로세스가 사용하는 가상 주소를 물리주소로 변환하는 것
  - 이를 통해 프로세스는 마음대로 사용자 데이터를 물리 메모리에 배치할 수 있음
- 가상 메모리는 세그멘테이션-페이징 혼합 방식으로 메모리 할당
- 가상 메모리 시스템에서 가상 주소는 메모리나 스왑영역 한 곳 중에 위치함
- 메모리 관리자는 가상 메모리와 물리 메모리를 1:1 매핑 테이블로 관리

## 세그멘테이션(배치정책)
- 가변분할 방식
- 세그멘테이션에서 프로그램은 함수나 모듈 등으로 세그먼트 구성
- 논리 주소 : 사용자와 프로세스, CPU가 바라보는 주소
- 실제 물리주소로 변환은 중간에서 메모리 관리자(MMU)가 세그멘테이션 테이블을 활용해 해줌
- 세그멘테이션 테이블에서 Base Address와 Bound Address 정보가 저장되고 이것을 이용해 물리 메모리 주소를 계산
#### 세그멘테이션의 주소변환 과정
1. 만약 CPU가 어떤 논리주소를 전달 해주면,
2. 메모리 관리자는 이 논리주소가 몇 번 세그먼트인지 알아내고,
3. 메모리 관리자 내의 Segment Table Base Register를 이용해 물리 메모리 내의 해당 세그멘테이션 테이블을 찾고,
4. 세그먼트 번호를 인덱스로 Base Address와 Bound Address를 찾음.
5. Bound Address는 세그먼트의 크기이고, 이를 CPU가 전달한 논리주소와 비교.
6. 만약 논리 주소가 Bound Address보다 작다면 논리주소와 Base Address를 더해 물리주소를 구하고,
7. 논리 주소가 Bound Address보다 크다면 메모리를 침범했다고 생각하고 에러를 발생시킴.
#### 세그멘테이션의 장점
- 메모리를 가변적으로 분할할 수 있음
- 코드 영역, 데이터 영역, 스택 영역, 힙 영역을 모듈로 처리할 수 있기 때문에 공유와 각 영역에 대한 메모리 접근 보호가 편리
#### 세그멘테이션의 단점
- 외부 단편화 발생

## 페이징(배치정책)
- 세그멘테이션의 외부 단편화를 해결하기 위해 고안됨
- 메모리를 할당할 때 정해진 크기의 페이지로 나눔
- 모든 페이지는 크기가 같기 때문에 관리가 굉장히 쉬워짐
- 일정한 크기로 나눴기 때문에 외부단편화 현상이 일어나지 않음
- 논리주소공간 : 사용자와 프로세스가 바라보는 주소공간
  - 페이지 : 논리주소공간을 일정한 크기로 균일하게 나눈 것
- 물리주소공간 : 실제 메모리에서 사용되는 주소공간
  - 프레임 : 페이지의 크기와 동일하게 나뉜 것
- 메모리 관리자는 페이지 테이블을 가지고 있음
#### 페이징의 주소변환 과정
1. 만약 CPU가 어떤 논리주소를 전달 해주면,
2. 메모리 관리자는 이 논리주소가 몇번 페이지인지, 오프셋은 얼마인지 알아내고,
3. 메모리 관리자 내의 Page Table Base Register(PTBR)을 이용해서 물리 메모리에 있는 해당 페이지 테이블을 찾고,
4. 페이지 번호를 인덱스로 프레임 번호를 알아냄.
    - 페이지 넘버 = 논리주소 / 페이지 크기 
5. 오프셋을 이용해 계산하여 물리주소로 변환함.
    - 오프셋 = 논리주소 % 페이지 크기 
6. 페이지 넘버(인덱스)에 해당하는 프레임에 오프셋을 더한 값이 실제 물리메모리 주소
    - 페이지 테이블에 프레임이 Invalid로 표시되어 있으면 스왑영역(하드디스크)에 저장되어 있다는 의미
#### 세그멘테이션과 페이징의 차이
- 세그멘테이션은 프로세스마다 크기가 달라 Bound Address를 가지고 있지만, 페이징은 모든 페이지의 크기가 동일해서 Bound Address를 가지고 있지 않음.
  - 따라서 페이징은 외부 단편화가 발생하지 않지만 내부 단편화가 발생함. (외부 단편화보다 상대적으로 심각하게 여기지 않음)
- 세그멘테이션은 논리적인 영역별로 세그먼트를 나눌 수 있지만, 페이징은 페이지의 크기가 고정되어 있어 페이지로 나누기 때문에 논리적인 영역별로 나눌 수 없음.
  - 따라서 페이징은 특정 영역만 딱 떼어내서 공유하거나 권한을 부여하는 것이 더 어려움
#### 페이지 테이블의 크기
- 페이징에서 가장 신경써야 하는 것
- 각 프로세스마다 페이징 테이블을 가지고 있는데, 프로세스가 많아질수록 페이지 테이블도 많아지기 때문에 프로세스가 실제로 사용할 수 있는 메모리 영역이 줄어듦.
- 실제로 메모리 관리자가 참조하는 페이지 테이블도 물리 메모리의 운영체제 영역에 저장되어 있기 때문에 페이지 테이블 크기가 너무 크면 사용자 영역이 부족해짐
- 따라서 페이지 테이블의 크기를 적절하게 유지하는 것이 굉장히 중요

## 페이지드 세그멘테이션(배치정책)
- 세그멘테이션 + 페이징 혼합
### 메모리 접근 권한
- 메모리의 특정 번지에 부여된 권한
- 읽기, 쓰기, 실행 3가지
- 메모리 접근 권한에 대한 검사는 가상 주소에서 물리 주소로 변환될 때마다 일어남
- 권한을 위반하면 에러를 발생시킴
#### 프로세스 각 영역별 권한
- 코드 영역 : 읽기, 실행
- 데이터 영역 : 읽기, (쓰기)
- 스택 & 힙 영역 : 읽기, 쓰기
### 페이지드 세그멘테이션
- 세그멘테이션 테이블에 권한 비트를 추가
- Base Address는 페이지 넘버로 바뀜
- Bound Address는 이 세그먼트의 페이지 개수로 바뀜
1. 가상주소가 들어오면 가상주소를 이용해 몇 번 세그먼트인지 알아냄
2. 해당 세그먼트가 메모리 접근 권한을 위반하는지 검사
3. 접근 권한을 위반했으면 프로세스 종료
4. 위반하지 않으면 페이지 넘버와 페이지 개수를 가져옴
5. 페이지 넘버로 페이지 테이블에 접근해서 프레임 번호를 가져옴
6. 물리 메모리내에 해당 프레임에 접근해서 그 위치에서 페이지 개수를 더해 물리 주소를 구함
7. 만약 물리 메모리에 해당 프레임이 없다면 스왑영역에서 물리메모리로 가져옴
#### 페이지드 세그멘테이션 단점
- 물리메모리에 접근하기 위해서 메모리에 접그을 두 번 해야한다는 것
  - 첫 번째는 세그멘테이션 테이블을 참조할 때
  - 두 번째는 페이지 테이블을 참조할 때
- 이러한 단점 때문에 현대 OS에서는 페이징과 페이지드 세그멘테이션 기법을 적절히 섞어서 사용

## 디맨드 페이징(가져오기 정책)
- 프로세스는 코드, 데이터, 힙, 스택 영역이 모두 올라가는 것이 아니라, 필요한 부분만 메모리에 올려서 사용
### 지역성 이론
- 90:10 법칙 : 90%의 시간이 10%의 코드에서 실행된다는 것
- 조만간 쓰일 데이터만 메모리에 올리고 당분간 필요하지 않은 것 같은 데이터는 스왑영역으로 보내 성능을 향상시킴
#### 공간의 지역성
- 현재 위치와 가까운 데이터에 접근할 확률이 높음
#### 시간의 지역성
- 최근에 접근했던 데이터가 오래 전에 접근했던 데이터보다 접근할 확률이 높음
### 디맨드 페이징
- 조만간 필요할 것 같은 데이터를 메모리로 가져오고 쓰이지 않을 것 같은 데이터는 스왑영역으로 이동시키는 정책
- 스왑영역을 보조저장장치에 저장하는데, 성능향상을 위해선 스왑영역으로 데이터를 이동시키는 것을 최소화해야 함
- 스왑인 : 스왑영역에서 메인메모리로 데이터를 가져오는 것
- 스왑아웃 : 물리메모리에서 스왑영역으로 데이터를 보내는 것
### 메모리 계층구조
- 메모리는 레지스터, 캐시, 메인 메모리, 보조저장장치로 나눌 수 있음
- 레지스터는 CPU에 존재하고, CPU의 한 사이클에 접근할 수 있어 굉장히 빠름
- 캐시는 CPU의 수 사이클에서 수십 사이클에 접근할 수 있고
- 메인 메모리는 수백 사이클이 걸림
- 보조저장장치에는 수백만 사이클이 걸려 굉장히 오래 걸림
### 페이지 테이블 엔트리(PTE)
- 가상주소가 주어지면 메모리 관리자는 페이지 테이블을 참조해서 물리 메모리가 있는 프레임을 알아내거나 스왑영역의 위치를 알아내야 함
- 이를 위해 페이지 테이블에는 여러 가지 비트가 존재
- 페이지 테이블을 이루고 있는 한 행을 페이지 테이블 엔트리(PTE)라고 함
  - 접근 비트
    - 페이지가 메모리에 올라온 후 데이터에 접근이 있었는지 알려주는 비트
    - 메모리에 읽기나 실행 작업을 했다면 1로 바뀜
  - 변경 비트
    - 페이지가 메모리에 올라온 후 데이터의 변경이 있었는지 알려주는 비트
    - 메모리에 쓰기 작업을 했으면 1로 바뀜
  - 유효 비트
    - 페이지가 물리 메모리에 있는지 알려주는 비트
    - 유효 비트가 1이라면 페이지가 스왑영역에 있고 0이라면 물리 메모리에 있다는 의미
  - 읽기, 쓰기, 실행 비트
    - 권한 비트, 해당 메모리에 접근 권한이 있는지 검사하는 비트
### 프로세스가 가상 메모리에 접근 요청을 했을 때
- 메모리 관리자는 페이지 테이블을 보고 물리 메모리의 프레임을 찾아내는데,
- 만약 물리 메모리에 없다면 Page Fault라는 인터럽트를 발생시킴
- Page Fault가 발생하면, 보조저장장치의 스왑영역에 접근하게 되고, 해당 프로세스는 대기 상태가 됨
- 스왑 영역의 데이터가 메모리로 올라가는 작업을 시작하고, 
- 메모리로 올라갔다면 대기 상태에 있던 프로세스는 다시 실행하게 됨

### 가상메모리 주소가 물리메모리와 스왑영역에서 참조되는 방법 (6:0  4~)
- 스왑이 필요 없는 경우
- 스왑 영역에 있는 데이터를 참조하는 경우
- 물리메모리가 꽉 찼을 때 스왑영역에 있는 데이터를 참조하는 경우

## 페이지 교체 정책
- 메모리가 꽉 찼을 때 어떤 페이지를 스왑영역으로 보낼지 결정하는 것
### 무작위 방법
- 지역성을 고려하지 않기 때문에 자주 사용되는 페이지가 선택될 때도 있어 성능이 별로 좋지 않음
- 거의 사용되지 않음
### FIFO(First In First Out)
- 메모리에 들어온지 가장 오래된 페이지를 선택하는 방법
- 자주 쓰이는 페이지가 먼저 들어왔다는 이유로 해당 페이지가 교체되면 공평하지 않음
- 구현이 간단하고 성능도 꽤 좋아서 조금 변형해서 많이 쓰임
- 하드웨어적으로 접근비트를 지원하지 않는 시스템에선 부득이하게 사용
### Optimum
- 앞으로 가장 오랫동안 쓰이지 않을 페이지를 선택하는 방법
- 사실상 구현이 불가능한 이론적인 선택방법
- 다른 알고리즘과 성능 비교를 할 때 참조용으로 쓰임
### LRU(Least Recently Used)
- 최근에 가장 사용이 적은 페이지를 선택하는 방법
- 지역성 이론의 시간의 지역성에 따르면 최근 사용한 데이터가 앞으로도 사용될 확률이 높기 때문에 최근에 가장 사용을 적게한 페이지가 앞으로도 사용될 확률이 적다는 결론
- 실제로도 Optimum 알고리즘에 근접한 성능
- 하지만 프로그램이 지역성을 뛰지 않을 땐 성능이 떨어지게 됨
- 페이지 테이블 엔트리는 여러 개의 비트와 페이지 넘버가 저장된다고 했는데, 이곳에 시간을 기록하려면 비트가 많이 필요
- 따라서 실제 LRU를 구현할 때는 접근 비트를 이용해서 LRU에 근접하게 구현

### 빌레이디의 역설
- FIFO의 가장 큰 단점을 설명
- Page Fault를 줄이려고 메모리를 더 늘려서 프레임의 수를 늘렸는데 오히려 Page Fault가 더 많이 발생하는 현상
- FIFO에서만 발생, LRU에서는 발생하지 않음

### LRU 구현의 어려움
- 시간을 기록해야하는 LRU는 구현이 힘듬
- 시간을 기록할 bit가 많이 필요할 뿐만 아니라,
- 많은 bit가 있어도 시간이 아주 오래 지난다고 가정하면 어쩔 수 없이 오버플로우가 발생 -> 시간을 올바르게 표현할 수 없어짐

### Clock Algorithm
- LRU를 비슷하게 구현한 알고리즘
- 접근 비트 하나만 이용
- 일정 시간마다 모든 페이지의 접근 비트를 0으로 초기화
- 접근 비트의 초기값은 0
- 만약 페이지가 참조되었다면 1로 설정
- 일정 시간마다 페이지가 참조되었는지 확인할 수 있음
- 페이지를 원형으로 연결
- 스왑영역으로 옮길 페이지를 포인터로 가르키는데, 이 포인터를 클락 핸드라고 함
- 클락 헤드는 시계 방향으로 회전
- 만약 Page Fault가 발생해서 스왑영역으로 보내야하는 상황이 나오면 클락 핸드는 현재 참조하고 있는 페이지의 접근 비트를 봄
- 만약 접근 비트가 1이라면 해당 접근 비트를 0으로 바꾸고 클락 핸드가 다음 페이지를 가르킴
- 이렇게 반복하다가 접근 비트가 0인 페이지를 발견하면 해당 페이지를 스왑영역으로 보냄

### Enhanced Clock Algorithm
- 접근 비트만 이용하는 것이 아니라 변경비트까지 봄
- 스왑영역으로 보내지는 가장 순위가 높은 것은 접근비트가 0이고 변경비트도 0인 페이지
- 그 다음은 접근비트가 0, 변경 비트가 1인 페이지
- 그 다음은 접근비트가 1, 변경 비트가 0인 페이지
- 마지막으로 접근비트가 1, 변경 비트가 1인 페이지

### 2차 기회 페이지 교체 알고리즘
- FIFO를 향상시킨 알고리즘
- FIFO 방식에서 자주 사용되는 페이지에게는 또 한번의 기회를 주는 것
- FIFO 방식과 동일하게 작동, 만약 Page Fault없이 페이지 접근에 성공했다면 해당 페이지를 큐의 맨 뒤로 이동시켜 수명을 연장시켜주는 방식
- 이 알고리즘의 성능은 LRU보다는 안좋고 FIFO보다는 좋음
