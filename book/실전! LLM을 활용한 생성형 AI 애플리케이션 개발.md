# [실전! LLM을 활용한 생성형 AI 애플리케이션 개발](https://search.shopping.naver.com/book/catalog/51343487620?cat_id=50010920&frm=PBOKPRO&query=LLM%EC%9D%84+%ED%99%9C%EC%9A%A9%ED%95%9C+%EC%83%9D%EC%84%B1%ED%95%9C+AI+%EC%95%A0%ED%94%8C%EB%A6%AC%EC%BC%80%EC%9D%B4%EC%85%98+%EA%B0%9C%EB%B0%9C&NaPm=ct%3Dmbrba3xs%7Cci%3Ddaff96b27e16b2ea0c64714f63db8ef19f50a34d%7Ctr%3Dboknx%7Csn%3D95694%7Chk%3Df13e348c65944f0ffbf1932a5467a18d6c308d60)
- 지은이: 발렌티나 알토
- 출판사: 위키북스
- 읽은 날짜: 2025.06.11 ~ 2025.


## 이 책을 최대한 활용하려면
- LLM이 무엇인지, 아키텍처는 무엇인지, LLM이 왜 AI의 혁명을 일으키고 있는지에 대한 이론적 토대 제공
- 랭체인 프레임워크 사용하는 방법 안내

## PART 01. 대규모 언어 모델 기초
## 01. 대규모 언어 모델 소개
- LLM의 아키텍처만이 그 모델의 작동 방식을 결정짓는 유일한 요소는 아니다.
    - '모델이 무엇을 아는지'는 훈련 데이터셋에 따라 달라지며,
    - '사용자의 요청에 따라 그 지식을 얼마나 잘 적용하는지'는 평가 지표에 따라 달라진다.
- 1 토큰 ~= 영문 4자 ~= 3/4 단어

### 1.4 기본 모델과 맞춤형 모델 비교
#### 1.4.1 모델을 맞춤화하는 방법
- 비모수적 지식 확장
  - 외부 정보 출처에 접근하여 사용자의 질의에 응답하면서 모수적 지식을 통합할 수 있다.
  - 모수적 지식 = LLM의 매개변수에 내재한 지식
  - 비모수적 지식 = 모델에 첨부할 수 있는 지식
- 퓨삿(Few-Shot) 학습
  - LLM에 새로운 작업을 수행하도록 요청할 때 적은 수의 예시가 포함된 메타프롬프트를 준다.
- 미세 조정(fine-tuning)
  - 과업에 특화된 소규모의 데이터셋을 사용해 파운데이션 모델을 특정 애플리케이션에 맞춤화


## 02. AI 기반 애플리케이션을 위한 LLM

### 2.1 LLM은 소프트웨어 개발을 어떻게 변화시키는가
- 기술적 측면에서, LLM을 애플리케이션에 통합하려면 REST API 호출을 통해 이를 내장하고 AI 오케스트레이터로 관리해야 한다.
  - 즉, API 호출을 통해 LLM과 원활하게 통신할 수 있는 아키텍처 구성 요소를 설정해야 한다.

### 2.2 코파일럿 시스템
- 코파일럿이란, 사용자와 협력하며 정보 검색, 블로그 작성 및 게시, 아이디어 브레인스토밍, 코드 검토 및 생성 등 다양한 활동을 지원하는 AI 비서(assistant)를 의미

### 2.3 LLM을 애플리케이션에 통합하기 위한 AI 오케스트레이터 소개
#### 2.3.1 AI 오케스트레이터의 주요 구성 요소
- 과거에는 AI 모델을 만드는 데 집중했찌만, 이제는 이미 만들어진 모델을 잘 활용하는 것이 더 중요해졌다.
#### 2.3.2 랭체인
- LangChain은 언어 모델로 구동되는 애플리케이션을 개발하기 위한 프레임워크
  - 데이터 인식 및 에이전트 기능을 갖추고 있어 외부 환경과 상호 작용할 수 있음.
  - 프롬프트, 메모리, 플러그인 등 언어 모델에 필요한 구성 요소에 대한 모듈식 추상화를 제공
  - 사전 구축된 체인도 제공. 특정 사용 사례에 맞게 미리 구축하거나 커스텀 가능.
- 체인
  - 미리 정해진 일련의 행동 및 LLM 호출
  - LLM을 서로 다른 컴포넌트와 연결해야 하는 복잡한 애플리케이션을 쉽게 구축할 수 있게 해줌.
- 에이전트
  - LLM 기반 애플리케이션 내에서 의사 결정을 주도하는 개체
  - 일련의 도구에 접근할 수 있으며 사용자 입력과 상황에 따라 어떤 도구를 호출할지 결정할 수 있음.
  - 에이전트는 동적이고 적응력이 뛰어나므로 상황이나 목표에 따라 행동을 변경하거나 조정할 수 있음.
#### 2.3.5 프레임워크 선택 방법
- 선호하는 프로그래밍 언어
- 만들고자 하는 자연어 과업의 유형과 복잡성
- 커스텀 지원 수준
- 레퍼런스 양과 품질


## 03. 애플리케이션에 적합한 LLM 선택
- LLM마다 아키텍처, 크기, 훈련 데이터, 기능 및 제한 사항이 다르다.
  - 이는 솔루션의 성능, 품질, 비용에 큰 영향을 미치므로, LLM 선택은 간단한 결정이 아니다.

### 3.1 시장에서 가장 유망한 LLM 소개
#### 3.1.1 독점 모델
- 사기업이 개발 및 소유하는 모델 (코드가 공개되지 않음.)
- 고객 지원과 유지보수, 안전 및 정렬 면에서 장점이 있다.
  - 정렬이란, LLM이 인간 사용자에게 유용하고 무해한 방식으로 작동하는 정도
- 복잡성과 훈련 데이터셋으로 일반화 측면에서 오픈소스 모델보다 우수한 성능을 보이는 경향이 있다.
- 앤트로픽은 안전 원칙에 부합하도록 하는 데 각별한 주의를 기울였다.
  - 정직하고 무해한 AI시스템을 만들어 모델을 더 안전하고 인간의 가치와 의도에 부합하게 만드는 것을 목표로 함.

#### 3.1.2 오픈소스 모델
- 미세 조정, 훈련 등을 사용자 마음대로 할 수 있음.

### 3.3 LLM 선택을 위한 의사결정 프레임워크
#### 3.3.1 고려 사항
- 크기와 성능
  - 모델이 클수록 성능이 좋지만, 입력을 처리하고 출력을 생성하는데 지연 시간과 비용이 높아질 수 있음.
- 비용 및 호스팅 전략
  - 모델 사용료
  - 모델 호스팅 비용
    - 오픈소스 모델의 경우 로컬에 다운로드해서 사용하며 자체 인프라를 요구함
- 맞춤화(Customization)
  - 미세 조정(fine-tuning)
    - 도메인에 더 잘 맞도록 LLM의 매개변수를 조정하는 프로세스
  - 처음부터 다시 훈련하기
- 도메인별 기능
  - 맞춤형 사용 사례를 염두에 두고 결정
  - 일반적인 기능을 포괄하는 모델이 필요하다면 GPT가 나을 수 있음.

## 02. LLM 기반 애플리케이션 개발
### 04. 프롬프트 엔지니어링
- 프롬프트는 LLM 성능에 막대한 영향을 미친다.
- 잘 짜여진 프롬프트는 LLM의 응답을 개선하고, 환각 및 편향과 관련된 위험을 줄일 수 있다.

### 4.1 프롬프트 엔지니어링이란?
- 프롬프트는 LLM이 텍스트 출력을 생성하도록 유도하는 텍스트 입력이다.
- 프롬프트 엔지니어링은 LLM에서 고품질의 관련성 높은 출력을 이끌어내는 효과적인 프롬프트를 설계하는 과정이다.

### 4.2 프롬프트 엔지니어링 기본
#### 4.2.1 명확한 지침을 제공
- 모델에 충분한 정보와 지침을 제공
  - 과업의 목표나 목적
  - 예상 출력 형식 또는 구조
  - 과업의 제약 또는 제한
  - 과업의 맥락 또는 배경
#### 4.2.2 복잡한 과업을 하위 과업으로 분할
- 과업이 너무 복잡하거나 모호하여 단일 프롬프트로 처리하기 어려울 경우, 여러 프롬프트로 해결할 수 있는 간단한 하위 과업들로 분할
- 예시
  - 텍스트 요약
    - 텍스트에서 요점 또는 키워드 추출
    - 요점 또는 키워드를 일관성 있고 유창하게 다시 작성
    - 원하는 길이 또는 형식에 맞게 요약 다듬기
  - 코드 생성
    - 코드에 사용할 언어, 프레임워크, 라이브러리 선택
    - 사용자 입력 또는 사양에 따라 코드의 함수 이름과 매개변수 및 반환값 목록 생성
    - 코드의 로직과 기능을 구현하는 함수 본문 생성
    - 코드와 사용법을 설명하는 주석 및 문서 추가
- 선택한 LLM마다 효과적인 프롬프트가 다를 수 있다.
#### 4.2.3 정당화를 요청
- LLM은 이전 토큰들을 기반으로 다음 토큰을 예측하는 방식으로 구축되어, 이전에 생성한 내용을 되돌아보지 않는다.
- 이로 인해, 매우 설득력 있는 방식으로 잘못된 콘텐츠를 출력할 수 있다.
- 프롬프트에 참조 및 정당화를 통해 LLM의 답변을 뒷받침하도록 할 수 있다.
- 정답은 맞았지만 추론 과정이 불분명한 경우 정당성을 묻는 것이 유용할 수 있다.
#### 4.2.4 여러 개의 출력을 생성해 가장 적합한 것을 선택
- LLM은 스스로 오류를 인식하고 수정할 수 없다.
  - LLM에게 물어보면 오류를 인정할 수는 있지만, 그 오류에 대해 생각하고 수정하도록 하려면 명시적으로 프롬프트를 줘야 한다.
- 모델에 여러 개의 응답을 생성하도록 유도한 다음, 가장 적합한 응답을 선택하게 할 수 있다.
#### 4.2.5 마지막에 지침을 반복
- LLM은 프롬프트의 모든 섹션에 동일한 가중치/중요도를 두어 처리하지 않는 경향이 있다.
- 프롬프트 끝에 주된 지침을 반복하면 모델이 자체적인 '최근성 편향'(최근의 데이터만 집중하는 경향)을 극복하는 데 도움이 될 수 있다.
#### 4.2.6 구분선을 사용
- 프롬프트 내에 구분선을 넣으면, 프롬프트의 구조를 더 명확하게 파악하는 경향이 있다.

### 4.3 고급 프롬프트 엔지니어링
#### 4.3.1 퓨샷 학습
- 퓨샷 학습이란, 우리가 모델에 어떻게 반응하기를 원하는지에 대한 예시를 제공하는 것
- 전체 아키텍처를 건드리지 않고도 모델 맞춤화를 가능하게 한다. 미세 조정 프로세스만큼 효과적일 수 있다.
#### 4.3.2 사고 연쇄(CoT)
- 사고 연쇄(Chain-of-Thought)는 중간 추론 단계를 통해 복잡한 추론을 가능하게 하는 기법
  - 모델이 자신의 추론을 설명하도록 유도하여 너무 빠르지 않도록 강제함으로써 잘못된 응답을 제공할 위험을 방지
#### 4.3.3 추론-행동(ReAct)
- ReAct(Reason and Act)는 추론과 행동을 LLM과 결합하는 일반적 패러다임
  - 언어 모델에 과업에 대한 언어적 추론 추적과 행동을 생성하도록 유도하고, 외부 리소스에서 정보를 얻기도 함.
  - 동적 추론을 수행하고 외부 정보를 기반으로 행동 계획을 조정할 수 있음.
- CoT와의 차이점
  - CoT : 과업에 대한 중간 추론 단계를 생성하라고 프롬프트
  - ReAct : 과업에 대한 중간 추론 단계와 행동 및 관찰을 생성하라고 프롬프트
- 환각 방지에 효과적임.

## 05. 애플리케이션에 LLM 통합하기.
- 책에서는 랭체인 프레임워크와 일반적으로 LLM 개발 환경에서 견고하게 유지되는 백본 개념(메모리, 벡터DB, 에이전트 등)에 대해 다룸

### 5.2 랭체인 시작하기
- 랭체인은 애플리케이션 내에서 LLM과 그 구성 요소를 쉽게 통합하고 오케스트레이션할 수 있도록 하는 경량 프레임워크
  - 주요 구성 요소: 모델 및 프롬프트 템플릿, 데이터 연결, 메모리, 체인, 에이전트
#### 5.2.1 모델과 프롬프트
- 랭체인은 OpenAI, 허깅페이스 허브 및 오픈소스 LLM 세계와의 통합을 지원
```python
# OpenAI 모델 사용해보기
from langchian_openai import OpenAI
llm = OpenAI(openai_api_key="apikey")
llm.invoke('do something')
```
- 프롬프트 템플릿
  - 언어 모델에 대한 프롬프트를 생성하는 방법을 정의하는 구성 요소
  - 변수, 플레이스홀더, 앞부분(prefix), 끝부분(suffix), 데이터와 과업에 따라 맞춤화할 수 있는 기타 요소를 포함.
  - 일반적으로 프롬프트 템플릿은 LLM의 종류에 구애받지 않음.
  ```python
  from langchain import PromptTemplate
  template = """문장: {sentence} -> {language}로 번역:"""
  prompt = PromptTemplate(template=template, input_variable=["sentence", "language"])
  prompt.format(sentence="고양이가 탁자 위에 있다.", language="영어")
  ```
- 예제 선택기
  - 언어 모델에 대한 프롬프트에 포함할 예제를 선택할 수 있는 랭체인 구성 요소
  - 언어 모델이 원하는 출력을 생성하도록 안내하는 텍스트 입력.
#### 5.2.2 데이터 연결
- 모델에 제공하려는 추가적인 지식을 제공하도록 할 수 있다.
- 문서 로드 -> 문서 변환기(+텍스트 분할기) -> 텍스트 임베딩 모델(+임베딩) -> 벡터 저장소 -> 검색기
  - 임베딩이 비모수적 지식을 LLM에 통합하는 핵심 단계
#### 5.2.3 기억(대화 메모리)
- 랭체인은 애플리케이션에서 기억 시스템을 설계할 수 있는 여러 모듈을 제공
#### 5.2.4 체인
- 체인은 일련의 작동과 LLM 호출을 미리 정해둔 것.
- 전반적으로 LangChain의 체인은 다양한 언어 모델과 과업을 단일 워크플로로 결합할 수 있는 강력한 방법이다.
  - 체인은 유연하고 확장 가능하며 사용하기 쉽다.
  - 사용자가 다양한 목적과 영역에서 언어 모델의 힘을 활용할 수 있게 한다.
#### 5.2.5 에이전트
- 에이전트 = LLM 기반 애플리케이션 내에서 의사 결정을 내리는 주체
  - 일련의 도구에 접근할 수 있다.
  - 사용자 입력과 상황에 따라 어떤 도구를 호출할지 결정한다.
  - 동적이고 적응력이 뛰어나다.
  - 체인은 작동 순서가 하드코딩되어 있지만, 에이전트는 올바른 순서로 올바른 작동을 계획하고 실행하는 것을 목표로 한다.

## 06. 대화형 애플리케이션 구축
### 6.1 대화형 애플리케이션 실행하기 (LangChain)
- `SystemMessage`: LLM에 제공하는 지침
- `HumanMessage`: 사용자의 입력 프롬프트
- `ConversationBufferMemory`같은 메모리 기능을 사용하면 사용자와 대화 내역을 LLM이 어느 정도 기억할 수 있다. (`langchain.memory`)
- `ConversationalRetrievalChain`을 사용해 비모수적 지식(벡터 DB 등)을 추가할 수 있다.
- `langchain.agents.agent_toolkits`의 `create_conversational_retrieval_agent` 함수를 통해 에이전트를 만들 수 있다.
  - `create_retriever_tool`로 tool을 생성하고 이 반환값을 등록할 수 있다.

### 6.2 스트림릿으로 프론트엔드 개발하기
- `Streamlit`은 웹 앱을 만들고 공유할 수 있는 파이썬 라이브러리
  - 간단한 명령어롤 사용해 시각적 요소(차트, 위젯, 표)를 생성할 수 있다.
  - 랭체인과 통합됨.
- 파이프라인의 출력을 사용자 친화적으로 볼 수 있음.

## 07. LLM을 사용한 검색 및 추천 엔진
### 7.4 LLM 기반 추천 시스템 구현
- '콜드 스타트'(초기 사용자 데이터가 없음)로 시작할 때는, 적당한 데이터셋을 먼저 가공하여 LLM을 학습시켜야 한다.
- 파이썬의 라이브러리(`tiktoken`)을 통해 데이터 임베딩 처리를 할 수 있다.


## 10. LLM으로 멀티모달 애플리케이션 구축
### 10.1 왜 멀티모달리티인가?
- 멀티모달리티: 다양한 형식의 데이터를 처리할 수 있는 모델의 능력
- 일반 인공 지능(AGI, Arificial General Intelligence)
  - 인간이 할 수 있는 모든 지적 과업을 수행할 수 있는 인공지능
- 에이전트, 모델에 따라 기본적으로 탑재된 시스템 프롬프트를 수정하여 특정 사용 사례에 맞게 맞춤화할 수 있다.

### 에이전트 방식과 체이닝(하드코딩) 방식 비교
- 에이전트 방식
  - 행동 순서를 LLM이 결정하여, 큰 유연성을 가짐.
  - 사고 과정을 제어할 수 없어 실수가 발생할 수 있음.
  - 프롬프트 엔지니어링이 필요.
  - 잘못된 사고 과정을 알아내기 위해 재현하기 어려울 수 있음.
  - 에이전트 하나만 관리하면 됨.
- 하드코딩 방식
  - 작업의 실행 순서를 완전히 제어할 수 있음.
  - 각 체인마다 개별적으로 테스트할 수 있음. 따라서 오류가 발생한 프로세스를 더 쉽게 식별 가능.
  - 각 체인마다 관리 포인트가 됨.
