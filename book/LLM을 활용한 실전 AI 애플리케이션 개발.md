# [LLM을 활용한 실전 AI 애플리케이션 개발](http://aladin.kr/p/9R7ZW)
- 지은이: 허정준
- 출판사: 책만
- 읽은 날짜: 2025.02. ~ 2025.

## 1부 LLM의 기초 뼈대 세우기
### 1장. LLM 지도
- LLM = 딥러닝 기반 언어 모델
  - LLM은 다음에 올 단어가 무엇일지 예측하면서 문장을 하나씩 만들어 가는 방식으로 텍스트를 생성한다. 이러한 모델을 언어 모델이라고 한다.
- 딥러닝이 머신러닝과 가장 큰 차이를 보이는 것 = "데이터 특징을 누가 뽑는가?"
  - 머신러닝 : 데이터의 특징을 연구자/개발자가 찾고 모델에 입력
  - 딥러닝 : 모델이 스스로 데이터의 특징을 찾고 분류하는 모든 과정을 학습
  - 즉, 데이터를 통해 학습하는 과정에서 그 데이터를 가장 잘 이해할 수 있는 방식을 함께 배운다.
- 임베딩
  - 컴퓨터는 숫자만 처리한다. 따라서 딥러닝 모델은 데이터의 의미와 특징을 숫자의 집합으로 표현한다. 이를 임베딩(embedding)이라 부른다.
  - 임베딩은 거리를 계산할 수 있다. 그래서 검색 및 추천, 분류, 이상치 탐지 등을 할 수 있다.
- 언어 모델링
  - 모델이 입력받은 텍스트의 다음 단어를 예측해 텍스트를 생성하는 방식
- 전이 학습(transfer learning)
  - 하나의 문제를 해결하는 과정에서 얻은 지식과 정보를 다른 문제를 풀 때 사용하는 방식
  - 사전 학습 : 대량의 데이터로 모델을 학습
  - 미세 조정(fine-tuning) : 특정한 문제를 해결하기 위한 데이터로 추가 학습
- 정렬(alignment)
  - LLM이 생성하는 답변을 사용자의 요청 의도에 맞추는 것
- LLM 의 미래
  - 멀티 모달 : 다양한 형태의 입력을 받을 수 있는 LLM (이미지, 오디오, 텍스트 ...)
  - 에이전트 : LLM을 활용해 주어진 상황을 인식하고 필요한 행동을 계획하고 의사결정을 내려 필요한 행동을 직접 수행하는 형태

### 2장. LLM의 중추, 트랜스포머 아키텍처 살펴보기
- 트랜스포머 아키텍처
  - 토큰
    - 거의 모든 자연어 처리 연산의 기본 단위
    - 보통 단어보다 짧은 텍스트 단위
  - 토큰화
    - 텍스트를 적절한 단위로 나누고 숫자 아이디를 부여하는 것
  - RNN(순환신경망)
    - 순차적 처리
    - 깊이가 깊어지면 문제가 발생함
  - 셀프 어텐션
    - 순차 처리 방식을 버리고, 입력된 문장 내의 각 단어가 서로 어떤 관련이 있는지 계산하여 각 단어의 표현(representation)을 조정
  - 사람이 글을 이해하는 것처럼 딥러닝 모델이 작동하도록 하려면 단어 사이의 관계를 계산해 관련이 있는지 찾고,관련이 있는 단어의 맥락을 포함시켜 단어를 재해석해야 한다.
    - 단어 사이의 관련성을 파악하기 위해 토큰 임베딩에 가중치를 도입한다. 이를 통해 내부적으로 토큰과 토큰 사이의 관계를 계산해서 적절히 주변 맥락을 반영하는 방법을 학습한다.
  - 인코더와 디코더로 구성
    - 인코더 집중 모델 : 구글 BERT
      - 자연어 이해에 강점
    - 디코더 집중 모델 : OpenAI GPT
      - 자연어 생성에 강점
    - 인코더-디코더 활용 모델 : 메타 BART, 구글 T5
      - 자연어 이해, 생성을 모두 활용하지만 매우 모델이 복잡하다.
- 주요 사전 학습 매커니즘
  - 인과적 언어 모델링
    - 문장의 시작부터 끝까지 순차적으로 단어를 예측
    - 이전에 등장한 단어들을 바탕으로 다음에 등장할 단어 예측
    - GPT 같은 생성 트랜스포머 모델에서 핵심적인 학습 방법
  - 마스크 언어 모델링
    - 입력 단어의 일부를 마스크 처리하고 그 단어를 맞추는 작업으로 모델을 학습

## 3장. 트랜스포머 모델을 다루기 위한 허길페이스 트랜스포머 라이브러리
- 트랜스포머 아키텍처 등장 이후, 각 회사마다 모델 활용법이 각기 달랐음.
- 허깅페이스 팀에서 개발한 트랜스포머 라이브러리는 공통된 인터페이스로 트랜스포머 모델을 활용할 수 있도록 지원함.
  - 현재 딥러닝 분야의 핵심 라이브러리.

### 허깅페이스 트랜스포머란
- 다양한 트랜스포머 모델을 통일된 인터페이스로 사용할 수 있도록 지원하는 오픈소스 라이브러리
  - 모델을 불러오는 방법, 모델의 함수, 학습 방법 등을 공통화
- 라이브러리
  - `transformers`: 트랜스포머 모델과 토크나이저를 활용할 때 사용
  - `datasets`: 트랜프포머 모델을 쉽게 학습하고 추론에 활용할 수 있도록 돕는다.

### 허깅페이스 허브
- 다양한 사전 학습 모델과 데이터셋을 탐색하고 쉽게 불러와 사용할 수 있도록 제공하는 온라인 플랫폼
- 수많은 사용자들이 자신의 학습한 모델과 데이터셋을 공개

### 허깅페이스 라이브러리 사용법
- 모델을 학습시키거나 추론하기 위해서는 모델, 토크나이저, 데이터셋이 필요하다. 이를 코드로 불러와 사용할 수 있다.
- `AutoModel.from_pretrained()`
  - `AutoModel`은 모델의 바디를 불러오는 클래스
  - `from_pretrained` 메서드에 모델 id를 전달해 적절한 클래스를 가져온다.

## 04. 말 잘 듣는 모델 만들기
- 언어 모델: 다음에 올 단어의 확률을 예측하는 모델

### 지도 미세 조정(supervised fine-tuning)
- LLM이 사용자 요청의 형식을 적절히 해석하고, 응답의 형태를 적절히 작성하며, 요청과 응답이 잘 연결되도록 추가 학습하는 것
- '지도'란 학습 데이터에 정답이 있다는 뜻이다.
- 정렬: LLM이 사용자의 요청에 맞춰 응답하도록 학습하는 것
- 지시 데이터셋(instruction dataset): 지도 미세 조정에 사용하는 데이터셋
  - OpenAI는 레이블러(labeler)를 고용해 지시 데이터셋을 구축했다.
  - 지시 데이터셋의 품질이 높을수록 모델의 답변 품질도 높아진다. 

### 리워드 모델(reward model)
- 지도 미세 조정을 마친 LLM에 지시사항을 입력해 여러 응답을 생성, 레이블러가 응답을 비교해 더 좋다고 판단하는 순서를 정해 선호 데이터셋을 구축한다.

### 강화 학습
  - 에이전트가 환경에서 행동을 한다.
  - 행동에 따라 환경의 상태가 바뀌고, 그 행동에 대한 보상이 생긴다.
  - 에이전트는 변화된 상태를 인식하고 보상을 받는다.
  - 에이전트는 가능하면 더 많은 보상을 받을 수 있도록 행동을 수정하면서 학습한다.
  - 이때 에이전트가 연속적으로 수행하는 행동의 모음을 에피소드라고 한다.

### RLHF(Reinforcement Learning from Human Feedback, 사람의 피드백을 활용한 강화 학습)
- PPO(Proximal Preference Optimization, 근접 정책 최적화): 보상 해킹 피하기
  - 보상 해킹: LLM이 보상을 높게 받는 데만 집중하는 것
  - 지도 미세 조정 모델을 기준으로 학습하는 모델이 너무 멀지 않게 가까운 범위에서 리워드 모델의 점수를 찾도록 한다.
- RLHF는 어렵다.
  - 리워드 모델을 학습시켜야 하는데, 리워드 모델의 성능이 좋지 않으면 일관성이 떨어지며 LLM의 학습이 제대로 되지 않는다.
  - 참고 모델, 학습 모델, 리워드 모델 총 3개가 필요하기 때문에 GPU 같은 리소스가 더 많이 필요하다.

### 강화 학습을 사용하지 않고 사람의 선호를 학습하는 방법
- 기각 샘플링(rejection sampling)
  - 단순히 가장 점수가 높은 데이터를 사용
  - 지도 미세 조정을 마친 LLM을 통해 여러 응답을 생성, 그중에서 리워드 모델이 가장 높은 점수를 준 응답을 모아 다시 지도 미세 조정을 수행한다.
- 직접 선호 최적화(Direct Preference Optimization, DPO)
  - 선호 데이터셋을 직접 학습
  - 선호 데이터셋으로 리워드 모델을 만들고 언어 모델의 출력을 평가하면서 강화 학습을 진행한다.
  - 별도의 리워드 모델이 필요하지 않다.
  - RLHF보다 선호되는 학습 방법

## 2부. LLM 길들이기
## 05. GPU 효율적인 학습
- 기본적으로 GPU에 딥러닝 모델 자체가 올라간다.
  - 딥러닝 모델은 수많은 행렬 곱셈을 위한 파라미터의 집합이다.
- 모델 파라미터의 데이터 타입이 더 많은 비트를 사용할수록 모델의 용량이 커지기 때문에 더 적은 비트로 모델을 표현하는 양자화 기술이 개발됐다.
  - 양자화 기술에서는 더 적은 비트를 사용하면서도 원본 데이터의 정보를 최대한 소실 없이 유지하는 것이 핵심이다.
